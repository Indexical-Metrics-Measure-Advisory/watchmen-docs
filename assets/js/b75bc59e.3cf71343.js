"use strict";(globalThis.webpackChunkwatchmen_docs=globalThis.webpackChunkwatchmen_docs||[]).push([[11245],{7551:(e,n,i)=>{i.d(n,{A:()=>r});const r=i.p+"assets/images/constant_value_parse-122b8ecd96247f5bdccd40b28314303e.png"},28453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>o});var r=i(96540);const t={},l=r.createContext(t);function s(e){const n=r.useContext(l);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),r.createElement(l.Provider,{value:n},e.children)}},41979:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"doll/pipeline-service","title":"Pipeline Service","description":"Pipeline service is the core of _watchmen_, topic data is processed, transformed and aggregated through pipelines which are predefined.","source":"@site/versioned_docs/version-16.2/040-doll/200-pipeline-service.md","sourceDirName":"040-doll","slug":"/doll/pipeline-service","permalink":"/docs/16.2/doll/pipeline-service","draft":false,"unlisted":false,"editUrl":"https://github.com/Indexical-Metrics-Measure-Advisory/watchmen-docs/tree/main/versioned_docs/version-16.2/040-doll/200-pipeline-service.md","tags":[],"version":"16.2","lastUpdatedBy":"luke0623","lastUpdatedAt":1770298247000,"sidebarPosition":200,"frontMatter":{"id":"pipeline-service","title":"Pipeline Service","sidebar_position":200},"sidebar":"sidebar","previous":{"title":"Data Service","permalink":"/docs/16.2/doll/data-service"},"next":{"title":"Inquiry Service","permalink":"/docs/16.2/doll/inquiry-service"}}');var t=i(74848),l=i(28453);const s={id:"pipeline-service",title:"Pipeline Service",sidebar_position:200},o="Pipeline Service",a={},c=[{value:"Pipeline",id:"pipeline",level:2},{value:"Pipeline Kernel and Surface",id:"pipeline-kernel-and-surface",level:2},{value:"Pipeline Trigger",id:"pipeline-trigger",level:3},{value:"Compiled Pipeline and Cache",id:"compiled-pipeline-and-cache",level:3},{value:"Parse Constant Parameter",id:"parse-constant-parameter",level:4},{value:"Decryption for Factor Value",id:"decryption-for-factor-value",level:3},{value:"Alarm Action",id:"alarm-action",level:3},{value:"Retry on Insert or Merge Row",id:"retry-on-insert-or-merge-row",level:3},{value:"Retry on Aggregation Topic",id:"retry-on-aggregation-topic",level:3},{value:"External Writers",id:"external-writers",level:2},{value:"Rest Writer",id:"rest-writer",level:3},{value:"Elasticsearch Writer",id:"elasticsearch-writer",level:3},{value:"Extend External Writer",id:"extend-external-writer",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"pipeline-service",children:"Pipeline Service"})}),"\n",(0,t.jsxs)(n.p,{children:["Pipeline service is the core of ",(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.em,{children:"watchmen"})}),", topic data is processed, transformed and aggregated through pipelines which are predefined.\nBefore go through the services and rest apis, let's learn about pipeline itself first."]}),"\n",(0,t.jsx)(n.h2,{id:"pipeline",children:"Pipeline"}),"\n",(0,t.jsx)(n.p,{children:"A pipeline is made up of the following materials:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"A prerequisite to decide current pipeline should be triggered or not,"}),"\n",(0,t.jsxs)(n.li,{children:["A set of stages to process trigger topic data. For each stage, including,","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"A prerequisite to decide current stage should be run or not,"}),"\n",(0,t.jsxs)(n.li,{children:["A set of units to process data. For each unit, including,","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"A prerequisite to decide current unit should be run or not,"}),"\n",(0,t.jsx)(n.li,{children:"A loop variable (from memory variables) to decide current unit is process a list or a single data,"}),"\n",(0,t.jsxs)(n.li,{children:["A set of actions to process data. There are different types of actions are built-in:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Alarm action,"}),"\n",(0,t.jsx)(n.li,{children:"Copy to variable action,"}),"\n",(0,t.jsx)(n.li,{children:"Read row action,"}),"\n",(0,t.jsx)(n.li,{children:"Read rows action,"}),"\n",(0,t.jsx)(n.li,{children:"Read factor action,"}),"\n",(0,t.jsx)(n.li,{children:"Read factors action,"}),"\n",(0,t.jsx)(n.li,{children:"Exists action,"}),"\n",(0,t.jsx)(n.li,{children:"Write row action,"}),"\n",(0,t.jsx)(n.li,{children:"Insert row action,"}),"\n",(0,t.jsx)(n.li,{children:"Insert or merge row action,"}),"\n",(0,t.jsx)(n.li,{children:"Write factor action,"}),"\n",(0,t.jsx)(n.li,{children:"Delete row action,"}),"\n",(0,t.jsx)(n.li,{children:"Delete rows action."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["To learn how to define a pipeline, visit ",(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"../web-client/admin/pipeline",children:"here"})})," for more details."]}),"\n",(0,t.jsx)(n.h2,{id:"pipeline-kernel-and-surface",children:"Pipeline Kernel and Surface"}),"\n",(0,t.jsx)(n.p,{children:"A set of services and rest apis are provided by pipeline kernel and surface."}),"\n",(0,t.jsx)(n.h3,{id:"pipeline-trigger",children:"Pipeline Trigger"}),"\n",(0,t.jsx)(n.p,{children:"Trigger a pipeline can be triggered synchronized,"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="synchronized"',children:'curl \\\n--location \\ \n--request POST \'http://host:port/pipeline/data?topic_name=a_topic&tenant_id=1\' \\\n--header \'Authorization: Bearer ...\' \\\n--header \'Content-Type: application/json\' \\\n--data-raw \'{\n    "code": "a_topic",\n    "data": {\n      ...\n    },\n    "triggerType": "insert-or-merge",\n    "tenantId": "1",\n    "traceId": "1"\n}\'\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"code"}),": topic name, case sensitive,"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"data"}),": a JSON object, topic data,"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"triggerType"}),": type of trigger, ",(0,t.jsx)(n.code,{children:"insert"}),", ",(0,t.jsx)(n.code,{children:"merge"}),", ",(0,t.jsx)(n.code,{children:"insert-or-merge"})," and ",(0,t.jsx)(n.code,{children:"delete"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"tenantId"}),": required when current user is super admin,"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"traceId"}),": provide only when client wants to control the trace id, otherwise engine will generate one if it is null or undefined."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Or can be triggered asynchronized,"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="asynchronized"',children:'curl \\\n--location \\ \n--request POST \'http://host:port/pipeline/data/async?topic_name=a_topic&tenant_id=1\' \\\n--header \'Authorization: Bearer ...\' \\\n--header \'Content-Type: application/json\' \\\n--data-raw \'{\n    "code": "a_topic",\n    "data": {\n      ...\n    },\n    "triggerType": "insert-or-merge",\n    "tenantId": "1",\n    "traceId": "1"\n}\'\n'})}),"\n",(0,t.jsx)(n.h3,{id:"compiled-pipeline-and-cache",children:"Compiled Pipeline and Cache"}),"\n",(0,t.jsx)(n.p,{children:"For performance consideration, pipeline is compiled on first invoking. Pipeline kernel caches compiled pipeline with same lifecycle of\npipeline itself."}),"\n",(0,t.jsx)(n.h4,{id:"parse-constant-parameter",children:"Parse Constant Parameter"}),"\n",(0,t.jsx)(n.p,{children:"It is very complex to parse and give the semantic to a constant parameter value string, following graph explains how to parse a constant\nparameter in different situations step by step."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Constant Value Parse",src:i(7551).A+"",width:"2211",height:"2072"})}),"\n",(0,t.jsx)(n.h3,{id:"decryption-for-factor-value",children:"Decryption for Factor Value"}),"\n",(0,t.jsxs)(n.p,{children:["Factor can be defined with an encryption, and in pipeline, data is read from storage into memory. Sometimes, the encrypted data must be\ndecrypted, in this case, to enable the ",(0,t.jsx)(n.code,{children:"DECRYPT_FACTOR_VALUE"}),", kernel will do decryption on read factor/factors/row/rows action."]}),"\n",(0,t.jsxs)(n.admonition,{type:"caution",children:[(0,t.jsx)(n.mdxAdmonitionTitle,{}),(0,t.jsx)(n.p,{children:"Decryption feature can be enabled only on pipeline processing, which means it will not be decrypted on retrieve topic data directly."})]}),"\n",(0,t.jsx)(n.h3,{id:"alarm-action",children:"Alarm Action"}),"\n",(0,t.jsx)(n.p,{children:"In the default implementation, there is only logging for alarm action, on error level with following format:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-logging",children:"[PIPELINE] [ALARM] [SEVERITY] MESSAGE\n"})}),"\n",(0,t.jsx)(n.p,{children:"Scan the log file to detect alarm by external services, such as filebeat."}),"\n",(0,t.jsx)(n.h3,{id:"retry-on-insert-or-merge-row",children:"Retry on Insert or Merge Row"}),"\n",(0,t.jsxs)(n.p,{children:["If insertion is failed when do ",(0,t.jsx)(n.code,{children:"insert-or-merge-row"})," action, typically it is caused by an unique index conflict exception. Kernel will try\nto do modification, and the logic is exactly same as ",(0,t.jsx)(n.code,{children:"merge-row"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"retry-on-aggregation-topic",children:"Retry on Aggregation Topic"}),"\n",(0,t.jsxs)(n.p,{children:["To avoid aggregation topic resource contention, there is an additional version property for each aggregation topic. In high concurrency\nscenarios, version optimistic lock conflict might be occurred. In this case, write action will do modification retrying, and if all retrying\nis failed, the last retry will use pessimistic lock to ensure success. Visit ",(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"../installation/config#pipeline-kernel",children:"here"})})," for more\ndetails about the retry settings."]}),"\n",(0,t.jsx)(n.h2,{id:"external-writers",children:"External Writers"}),"\n",(0,t.jsx)(n.p,{children:"There are two built-in external writers:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Standard restful writer,"}),"\n",(0,t.jsx)(n.li,{children:"Standard Elasticsearch writer."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"rest-writer",children:"Rest Writer"}),"\n",(0,t.jsx)(n.p,{children:"Like the following curl command,"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'curl \\\n--location \\ \n--request POST \'some_url\' \\\n--header \'Authorization: PAT ...\' \\\n--header \'Content-Type: application/json\' \\\n--data-raw \'{\n    "code": "eventCode",\n    "currentData": {\n      ...\n    },\n    "previousData: {\n      ...\n    },\n    "triggerType": "insert-or-merge"\n}\'\n'})}),"\n",(0,t.jsx)(n.h3,{id:"elasticsearch-writer",children:"Elasticsearch Writer"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.em,{children:(0,t.jsx)(n.code,{children:"(under construction)"})})})}),"\n",(0,t.jsx)(n.h3,{id:"extend-external-writer",children:"Extend External Writer"}),"\n",(0,t.jsx)(n.p,{children:"To extend an external writer,"}),"\n",(0,t.jsx)(n.p,{children:"Fork our repo, for server side,"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Find ",(0,t.jsx)(n.code,{children:"init_prebuilt_external_writers"})," in ",(0,t.jsx)(n.code,{children:"watchmen-pipeline-kernel"}),", build your own just follow standard restful writer,"]}),"\n",(0,t.jsx)(n.li,{children:"Register it,"}),"\n",(0,t.jsx)(n.li,{children:"Bingo!"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"For defined new external writer type in web client, you need to,"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Add data source types into ",(0,t.jsx)(n.code,{children:"ExternalWriterType"}),", which in ",(0,t.jsx)(n.code,{children:"external-writer-types.ts"}),","]}),"\n",(0,t.jsxs)(n.li,{children:["Add dropdown label into ",(0,t.jsx)(n.code,{children:"ExternalWriterTypeInput"}),", which in ",(0,t.jsx)(n.code,{children:"external-writer-type-input.tsx"}),","]}),"\n",(0,t.jsx)(n.li,{children:"Bingo!"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);